Pacman Game Testing Document
Overview
This document outlines the process and results of testing the Pacman game using manual unit testing, input/output testing, and exception handling in C++ without any testing framework. The goal is to ensure the game functions correctly, handles user interactions properly, and gracefully manages any errors.

1. Unit Testing
1.1 Approach
Manually create unit tests for each function within the classes.
Test both expected and edge cases to ensure comprehensive coverage.
Test individual functions in isolation to identify and isolate issues effectively.


1.2 Testing Methods
Unit Tests for Functions:
Each function within classes such as Pacman, Ghosts, and Maze will have specific manual tests.
Test cases will cover all possible inputs and expected behaviors.
Use stubbing and mocking techniques where necessary to isolate dependencies.
Conduct manual integration tests to ensure proper interactions between different components.


1.3 Criteria for Success
All manual tests should pass without any failures or errors.
Test coverage should aim for close to 100% of all functions.


1.4 Test Cases and Results
1.4.1 Pacman Class
Test Move Function:
Test valid moves within the maze boundaries.
Test invalid moves (e.g., moving through walls).
Result: All valid moves succeeded; invalid moves correctly restricted.


1.4.2 Ghosts Class
Test Chase Pacman:
Test ghost movement towards Pacman.
Test ghost behavior at intersections.
Result: Ghosts chased Pacman correctly; handled intersections as expected.


1.4.3 Maze Class
Test Load Maze:
Test loading a valid maze file.
Test handling of invalid or corrupted maze files.
Result: Valid mazes loaded correctly; errors logged for invalid files.

1.4.4 Test Eat Cherry:
Test eating a cherry and updating the score.
Test scenarios with no cherry present.
Result: Score updated correctly when pellet is eaten; no changes when no cherry.

1.4.5 Test Eat Pellet:
Test eating a pellet and updating the score.
Test scenarios with no pellet present.
Result: Score updated correctly when pellet is eaten; no changes when no pellet.

1.4.6 Test Eat SpeedDot:
Test eating a speed dot and updating the score.
Test scenarios with no speed dot present.
Result: Score updated correctly when pellet is eaten; no changes when no speed dot.


2. Input/Output Testing
2.1 Approach
Develop organized input/output tests to verify correct file operations and user interactions.
Use test files with predefined inputs and expected outputs to validate file reading and writing.
Simulate user interactions programmatically to ensure correct handling of user input.

2.2 Testing Methods
Test File Operations:
Test reading and writing functions for map files, high scores, and other relevant data.
Validate file integrity and content accuracy.

Test User Input Handling:
Simulate movement commands and menu interactions.
Test error handling for invalid inputs.

2.3 Criteria for Success
Program should accurately read and write data from files without corruption or loss.
User interactions should be intuitive and error-free, with proper error messages for invalid input.
Input/output tests should be documented and reproducible.

2.4 Test Cases and Results
2.4.1 File Operations
Test High Score Saving:
Test saving a high score to the file.
Test loading the high score from the file.
Result: High scores saved and loaded correctly without data loss.

2.4.2 User Input Handling
Test Movement Commands:
Simulate valid movement commands and verify response.
Simulate invalid commands and check error handling.
Result: Valid movements executed; errors handled gracefully for invalid commands.

3. Exception Handling
3.1 Approach
Implement exception handling mechanisms to gracefully handle unexpected inputs or situations.
Use try-catch blocks to capture and handle exceptions effectively.
3.2 Handling Errors
Log any errors encountered during runtime, including details such as error type and stack trace.
